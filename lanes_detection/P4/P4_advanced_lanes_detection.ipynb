{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Advanced Lanes Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in and make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The function cal_undistort takes an image, object points, and image points\n",
    "# performs the camera calibration, image distortion correction and \n",
    "# returns the undistorted image\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    # Use cv2.calibrateCamera() and cv2.undistort()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This function makes sure that each processed image is saved in the \n",
    "# appropriate folder \n",
    "def save_img(img, folder, fname, stage_name, col_map):\n",
    "    fname = fname.split('/')[1]\n",
    "    fname = fname.split('.')[0]\n",
    "    new_filename = fname + \"_\" + stage_name + '.jpg'    \n",
    "    mpimg.imsave(folder + \"/\" + new_filename, img,cmap=col_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Arrays to store object points and image points from all the images\n",
    "\n",
    "objpoints = [] # 3D points in real world space\n",
    "imgpoints = [] # 2D points in image plane \n",
    "\n",
    "# Prepare object points \n",
    "objp = np.zeros((6*9,3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2) # x,y coordinates\n",
    "\n",
    "# Create the undistorted_images directory within the camera_cal directory\n",
    "if not os.path.exists(\"camera_cal/undistorted_images\"):\n",
    "    os.makedirs(\"camera_cal/undistorted_images\")\n",
    "\n",
    "for fname in images:\n",
    "    # read in each image\n",
    "    img = mpimg.imread(fname)\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "    \n",
    "    # If corners are found, add object and image points \n",
    "    if ret == True:\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "        \n",
    "        # draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        \n",
    "        # get the undistorted version of the calibration image\n",
    "        undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "        \n",
    "        save_img(undistorted, \"camera_cal/undistorted_images\", fname, \"undist\", col_map = 'jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Computer Vision Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output\n",
    "\n",
    "def find_window_centroids(warped, window_width, window_height, margin):\n",
    "    window_centroids = [] # Store the (left,right) window centroid positions per level\n",
    "    window = np.ones(window_width) # Create our window template that we will use for convolutions\n",
    "    \n",
    "    # First find the two starting positions for the left and right lane by using np.sum to get the vertical image slice\n",
    "    # and then np.convolve the vertical image slice with the window template \n",
    "    \n",
    "    # Sum quarter bottom of image to get slice, could use a different ratio\n",
    "    l_sum = np.sum(warped[int(3*warped.shape[0]/4):,:int(warped.shape[1]/2)], axis=0)\n",
    "    l_center = np.argmax(np.convolve(window,l_sum))-window_width/2\n",
    "    r_sum = np.sum(warped[int(3*warped.shape[0]/4):,int(warped.shape[1]/2):], axis=0)\n",
    "    r_center = np.argmax(np.convolve(window,r_sum))-window_width/2+int(warped.shape[1]/2)\n",
    "    \n",
    "    # Add what we found for the first layer\n",
    "    window_centroids.append((l_center,r_center))\n",
    "    \n",
    "    past_centroids = []\n",
    "    # Go through each layer looking for max pixel locations\n",
    "    for level in range(1,(int)(warped.shape[0]/window_height)):\n",
    "        # convolve the window into the vertical slice of the image\n",
    "        image_layer = np.sum(warped[int(warped.shape[0]-(level+1)*window_height):int(warped.shape[0]-level*window_height),:], axis=0)\n",
    "        conv_signal = np.convolve(window, image_layer)\n",
    "        # Find the best left centroid by using past left center as a reference\n",
    "        # Use window_width/2 as offset because convolution signal reference is at right side of window, not center of window\n",
    "        offset = window_width/2\n",
    "        l_min_index = int(max(l_center+offset-margin,0))\n",
    "        l_max_index = int(min(l_center+offset+margin,warped.shape[1]))\n",
    "        l_center = np.argmax(conv_signal[l_min_index:l_max_index])+l_min_index-offset\n",
    "        # Find the best right centroid by using past right center as a reference\n",
    "        r_min_index = int(max(r_center+offset-margin,0))\n",
    "        r_max_index = int(min(r_center+offset+margin,warped.shape[1]))\n",
    "        r_center = np.argmax(conv_signal[r_min_index:r_max_index])+r_min_index-offset\n",
    "        # Add what we found for that layer\n",
    "        window_centroids.append((l_center,r_center))\n",
    "        past_centroids.append(np.average(window_centroids[-3:], axis = 0))\n",
    "\n",
    "    return past_centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient\n",
    "    dir_grad = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(dir_grad)\n",
    "    binary_output[(dir_grad > thresh[0]) & (dir_grad < thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel))\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    # Apply threshold\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return grad_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_frames = []\n",
    "previous_radii = []\n",
    "previous_positions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the undistorted directory \n",
    "if not os.path.exists(\"output_images/undistorted\"):\n",
    "    os.makedirs(\"output_images/undistorted\")\n",
    "# Create the binary directory \n",
    "if not os.path.exists(\"output_images/binary\"):\n",
    "    os.makedirs(\"output_images/binary\")\n",
    "# Create the warped directory \n",
    "if not os.path.exists(\"output_images/warped\"):\n",
    "    os.makedirs(\"output_images/warped\")\n",
    "# Create the lane_pixels directory \n",
    "if not os.path.exists(\"output_images/lane_pixels\"):\n",
    "    os.makedirs(\"output_images/lane_pixels\")\n",
    "# Create the polynomial directory \n",
    "if not os.path.exists(\"output_images/polynomial\"):\n",
    "    os.makedirs(\"output_images/polynomial\")\n",
    "\n",
    "    \n",
    "# This function processes each individual image coming from the video stream \n",
    "# and estimates where the lane lines are\n",
    "def image_pipeline(img, fname):\n",
    "    undistorted = cal_undistort(img, objpoints, imgpoints)\n",
    "    if fname != \"None\":\n",
    "        save_img(undistorted, \"output_images/undistorted\", fname, \"undistorted\", col_map = 'jet')\n",
    "        \n",
    "    s_thresh=(90, 255) \n",
    "    v_thresh=(200, 255) \n",
    "    sx_thresh=(20, 255) \n",
    "    sy_thresh=(10, 255) \n",
    "    \n",
    "    gradx = abs_sobel_thresh(undistorted, orient='x', thresh=sx_thresh)\n",
    "    grady = abs_sobel_thresh(undistorted, orient='y', thresh=sy_thresh)\n",
    "    hls = cv2.cvtColor(undistorted, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    s_channel = hls[:,:,2]\n",
    "    hsv = cv2.cvtColor(undistorted, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "    v_channel = hsv[:,:,2]\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(undistorted[:,:,0])\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1]) & (v_channel >= v_thresh[0]) & (v_channel <= v_thresh[1])] = 1\n",
    "\n",
    "    binary_final = np.zeros_like(s_channel)\n",
    "    binary_final[((gradx == 1) & (grady == 1) | (s_binary == 1))] = 255\n",
    "    if fname != \"None\":\n",
    "        save_img(binary_final, \"output_images/binary\", fname, \"binary\", col_map = 'gray')\n",
    "    \n",
    "    # Apply a birds-eye view's perspective transform\n",
    "    src = np.float32([[264, 678],[1042, 678],[686, 452],[596, 452]])\n",
    "    dst = np.float32([[320, 720],[960, 720],[960, 0],[320, 0]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    img_size = (binary_final.shape[1],binary_final.shape[0])\n",
    "    warped = cv2.warpPerspective(binary_final, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    if fname != \"None\":\n",
    "        save_img(warped, \"output_images/warped\", fname, \"warped\", col_map = 'gray')\n",
    "    \n",
    "    # Apply a sliding window search\n",
    "    # window settings\n",
    "    window_width = 30 \n",
    "    window_height = 80 # Break image into 9 vertical layers since image height is 720\n",
    "    margin = 30 # How much to slide left and right for searching\n",
    "    window_centroids = find_window_centroids(warped, window_width, window_height, margin)\n",
    "    # If we found any window centers\n",
    "    if len(window_centroids) > 0:\n",
    "        # Points used to draw all the left and right windows\n",
    "        l_points = np.zeros_like(warped)\n",
    "        r_points = np.zeros_like(warped)\n",
    "\n",
    "        # Go through each level and draw the windows \t\n",
    "        for level in range(0,len(window_centroids)):\n",
    "            # Window_mask is a function to draw window areas\n",
    "            l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "            r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "            # Add graphic points from window mask here to total pixels found \n",
    "            l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "            r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "        # Draw the results\n",
    "        template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "        zero_channel = np.zeros_like(template) # create a zero color channle \n",
    "        template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "        warpage = np.array(cv2.merge((warped,warped,warped)),np.uint8) # making the original road pixels 3 color channels\n",
    "        output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results \n",
    "    # If no window centers found, just display orginal road image\n",
    "    else:\n",
    "        output = np.array(cv2.merge((warped,warped,warped)),np.uint8)\n",
    "    if fname != \"None\":\n",
    "        save_img(output, \"output_images/lane_pixels\", fname, \"lane_pixels\", col_map = 'jet')\n",
    "    \n",
    "    # Apply polynomial fits to the left and right lanes\n",
    "    if len(window_centroids) > 0:\n",
    "        leftx = []\n",
    "        lefty = []\n",
    "        for (x,y), value in np.ndenumerate(l_points):\n",
    "            if l_points[x,y] == 255:\n",
    "                leftx.append(y)\n",
    "                lefty.append(x)\n",
    "        rightx = []\n",
    "        righty = []\n",
    "        for (x,y), value in np.ndenumerate(r_points):\n",
    "            if r_points[x,y] == 255:\n",
    "                rightx.append(y)\n",
    "                righty.append(x) \n",
    "    \n",
    "        ploty = np.linspace(0, 719, num=720)\n",
    "        left_fit = np.polyfit(lefty, leftx, 2) \n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        mark_size = 3\n",
    "        fig = plt.figure()\n",
    "        plt.plot(leftx, lefty, 'o', color='red', markersize=mark_size)\n",
    "        plt.plot(rightx, righty, 'o', color='blue', markersize=mark_size)\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(0, 720)\n",
    "        plt.plot(left_fitx, ploty, color='green', linewidth=3)\n",
    "        plt.plot(right_fitx, ploty, color='green', linewidth=3)\n",
    "        plt.gca().invert_yaxis()\n",
    "        if fname != \"None\":\n",
    "            fname_n = fname\n",
    "            fname_n = fname_n.split('/')[1]\n",
    "            fname_n = fname_n.split('.')[0]\n",
    "            new_filename = fname_n + \"_\" + \"poly\" + '.jpg'  \n",
    "            fig.savefig('output_images/polynomial/' + new_filename)\n",
    "        \n",
    "        # Calculate the curvature of the road and the position of the vehicle with respect to \n",
    "        # the center of the lane\n",
    "    \n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "        # Fit new polynomials to x,y in world space\n",
    "        left_fit_cr = np.polyfit(np.asarray(lefty)*ym_per_pix, np.asarray(leftx)*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(np.asarray(righty)*ym_per_pix, np.asarray(rightx)*xm_per_pix, 2)\n",
    "        # Calculate the radii of curvature\n",
    "        y_bottom_left = np.max(lefty)\n",
    "        y_bottom_right = np.max(righty)\n",
    "        left_curverad = ((1 + (2*left_fit_cr[0]*y_bottom_left*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        right_curverad = ((1 + (2*right_fit_cr[0]*y_bottom_right*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "        # Now our radius of curvature is in meters\n",
    "        #print(left_curverad, 'm', right_curverad, 'm')\n",
    "        avg_curve_rad = (left_curverad + right_curverad)/2\n",
    "        if fname == \"None\":\n",
    "            previous_radii.append(avg_curve_rad)\n",
    "            avg_curve_rad = np.average(previous_radii[-10:])\n",
    "        radius = \"Radius of Curvature = \" + str(avg_curve_rad) + \" m\"\n",
    "        center_lane = np.average(window_centroids[0])\n",
    "        center_offset = (center_lane - warped.shape[1]/2)*xm_per_pix\n",
    "        if fname == \"None\":\n",
    "            previous_positions.append(center_offset)\n",
    "            center_offset = np.average(previous_positions[-10:])\n",
    "        if center_offset < 0:\n",
    "            position = \"left\"\n",
    "        else:\n",
    "            position = \"right\"\n",
    "        pos_vehicle = \"Vehicle is \" + str(center_offset) + \" m \" + position + \" of center\"\n",
    "        if fname != \"None\":\n",
    "            print(fname)\n",
    "            print(radius)\n",
    "            print(pos_vehicle)\n",
    "        \n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "        \n",
    "        left_top = left_fitx[0]\n",
    "        left_bottom = left_fitx[-1]\n",
    "        right_top = right_fitx[0]\n",
    "        right_bottom = right_fitx[-1]\n",
    "        \n",
    "        if len(previous_frames) > 0: \n",
    "            if (right_top - left_top) < 610 or (right_bottom - left_bottom) < 610 or (right_top - left_top) > 850 or (right_bottom - left_bottom) > 850:\n",
    "                color_warp = previous_frames[-1]\n",
    "            else:\n",
    "                previous_frames.append(color_warp)\n",
    "        else:\n",
    "            previous_frames.append(color_warp)\n",
    "                \n",
    "        # Check that the new detected lane is similar to the one detected in the \n",
    "        # previous frame\n",
    "        if fname == \"None\":\n",
    "            if not previous_frames:\n",
    "                previous_frames.append(color_warp)\n",
    "            else:\n",
    "                color_warp_gray = cv2.cvtColor(color_warp, cv2.COLOR_RGB2GRAY) \n",
    "                previous_gray = cv2.cvtColor(previous_frames[-1], cv2.COLOR_RGB2GRAY)  \n",
    "                non_similarity = cv2.matchShapes(color_warp_gray,previous_gray,1,0.0)\n",
    "                if non_similarity > 0.002: \n",
    "                    color_warp = previous_frames[-1]\n",
    "                else:\n",
    "                    previous_frames.append(color_warp)\n",
    "        \n",
    "        # Inverse perspective transform\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, Minv, (binary_final.shape[1], binary_final.shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(undistorted, 1, newwarp, 0.3, 0)\n",
    "        cv2.putText(result,radius,(50,50),cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 255),2)\n",
    "        cv2.putText(result,pos_vehicle,(50,100) , cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 255),2)\n",
    "        if fname != \"None\":\n",
    "            save_img(result, \"output_images\", fname, \"final\", col_map = 'jet')\n",
    "        plt.imshow(result)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images/straight_lines1.jpg\n",
      "Radius of Curvature = 12198.2221233 m\n",
      "Vehicle is -0.00660714285714 m left of center\n",
      "test_images/straight_lines2.jpg\n",
      "Radius of Curvature = 11216.48909 m\n",
      "Vehicle is -0.0118928571429 m left of center\n",
      "test_images/test1.jpg\n",
      "Radius of Curvature = 2466.16234612 m\n",
      "Vehicle is 0.196892857143 m right of center\n",
      "test_images/test2.jpg\n",
      "Radius of Curvature = 572.28853645 m\n",
      "Vehicle is 0.262964285714 m right of center\n",
      "test_images/test3.jpg\n",
      "Radius of Curvature = 651.133279375 m\n",
      "Vehicle is 0.215392857143 m right of center\n",
      "test_images/test4.jpg\n",
      "Radius of Curvature = 6688.5064407 m\n",
      "Vehicle is 0.288071428571 m right of center\n",
      "test_images/test5.jpg\n",
      "Radius of Curvature = 641.156354907 m\n",
      "Vehicle is 0.0224642857143 m right of center\n",
      "test_images/test6.jpg\n",
      "Radius of Curvature = 637.855729988 m\n",
      "Vehicle is 0.354142857143 m right of center\n"
     ]
    }
   ],
   "source": [
    "# Create the output_images directory \n",
    "if not os.path.exists(\"output_images\"):\n",
    "    os.makedirs(\"output_images\")\n",
    "    \n",
    "# Read in and make a list of the test images\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fname in test_images:\n",
    "    # read in each image\n",
    "    img = mpimg.imread(fname)\n",
    "    \n",
    "    result = image_pipeline(img, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test on Videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "previous_frames = []\n",
    "previous_radii = []\n",
    "previous_positions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    result = image_pipeline(image, \"None\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [59:23<00:02,  2.61s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "CPU times: user 56min 17s, sys: 3min 19s, total: 59min 36s\n",
      "Wall time: 59min 24s\n"
     ]
    }
   ],
   "source": [
    "project_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "challenge_video_output = 'challenge_video_output.mp4'\n",
    "clip2 = VideoFileClip(\"challenge_video.mp4\")\n",
    "challenge_video_clip = clip2.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time challenge_video_clip.write_videofile(challenge_video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "harder_challenge_video_output = 'harder_challenge_video_output.mp4'\n",
    "clip3 = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "harder_challenge_video_clip = clip3.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time harder_challenge_video_clip.write_videofile(harder_challenge_video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
